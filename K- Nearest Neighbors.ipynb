{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f464e4b9-4b84-4595-a381-219a32b19e9f",
   "metadata": {},
   "source": [
    "## Assignment 6: K- Nearest Neighbors\n",
    "### DTSC 680: Applied Machine Learning\n",
    "\n",
    "### Name: Haneefudin Rasheed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e30e22",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a92de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import zipfile\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650fafc",
   "metadata": {},
   "source": [
    "# 1 importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250b7bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>._cap_shape</th>\n",
       "      <th>._cap_surface</th>\n",
       "      <th>._cap_color</th>\n",
       "      <th>._bruises?</th>\n",
       "      <th>._odor</th>\n",
       "      <th>._gill_attachment</th>\n",
       "      <th>._gill_spacing</th>\n",
       "      <th>._gill_size</th>\n",
       "      <th>._gill_color</th>\n",
       "      <th>...</th>\n",
       "      <th>._stalk_surface_below_ring</th>\n",
       "      <th>._stalk_color_above_ring</th>\n",
       "      <th>._stalk_color_below_ring</th>\n",
       "      <th>._veil_type</th>\n",
       "      <th>._veil_color</th>\n",
       "      <th>._ring_number</th>\n",
       "      <th>._ring_type</th>\n",
       "      <th>._spore_print_color</th>\n",
       "      <th>._population</th>\n",
       "      <th>._habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class ._cap_shape ._cap_surface ._cap_color ._bruises? ._odor  \\\n",
       "0     p           x             s           n          t      p   \n",
       "1     e           x             s           y          t      a   \n",
       "2     e           b             s           w          t      l   \n",
       "3     p           x             y           w          t      p   \n",
       "4     e           x             s           g          f      n   \n",
       "\n",
       "  ._gill_attachment ._gill_spacing ._gill_size ._gill_color  ...  \\\n",
       "0                 f              c           n            k  ...   \n",
       "1                 f              c           b            k  ...   \n",
       "2                 f              c           b            n  ...   \n",
       "3                 f              c           n            n  ...   \n",
       "4                 f              w           b            k  ...   \n",
       "\n",
       "  ._stalk_surface_below_ring ._stalk_color_above_ring  \\\n",
       "0                          s                        w   \n",
       "1                          s                        w   \n",
       "2                          s                        w   \n",
       "3                          s                        w   \n",
       "4                          s                        w   \n",
       "\n",
       "  ._stalk_color_below_ring ._veil_type ._veil_color ._ring_number ._ring_type  \\\n",
       "0                        w           p            w             o           p   \n",
       "1                        w           p            w             o           p   \n",
       "2                        w           p            w             o           p   \n",
       "3                        w           p            w             o           p   \n",
       "4                        w           p            w             o           e   \n",
       "\n",
       "  ._spore_print_color ._population ._habitat  \n",
       "0                   k            s         u  \n",
       "1                   n            n         g  \n",
       "2                   n            n         m  \n",
       "3                   k            s         u  \n",
       "4                   n            a         g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "zip_file_path = 'mushrooms.zip'\n",
    "extracted_folder_path = 'mushrooms_extracted'\n",
    "\n",
    "# Unzipping the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "# Define the paths to the extracted .names and .data files\n",
    "names_file_path = os.path.join(extracted_folder_path, 'mushrooms/agaricus-lepiota.names')\n",
    "data_file_path = os.path.join(extracted_folder_path, 'mushrooms/agaricus-lepiota.data')\n",
    "\n",
    "# Function to extract column names from the .names file\n",
    "def extract_column_names(file_path):\n",
    "    column_names = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    attributes_section_started = False\n",
    "    for line in lines:\n",
    "        if 'Attribute Information:' in line:\n",
    "            attributes_section_started = True\n",
    "            continue  # Skip the title line of the section\n",
    "        if attributes_section_started:\n",
    "            if ':' in line:  # Check for the presence of ':' to identify attribute lines\n",
    "                attribute_name = line.split(':')[0].strip()\n",
    "                # Handle numeric prefixes in attribute names, if any\n",
    "                attribute_name = ''.join([i for i in attribute_name if not i.isdigit()]).strip()\n",
    "                # Format attribute name\n",
    "                attribute_name = attribute_name.replace('-', '_').replace(' ', '_')\n",
    "                column_names.append(attribute_name)\n",
    "            elif line.strip() == '':  # An empty line might indicate the end of the section\n",
    "                break\n",
    "\n",
    "    # Ensure the first column is correctly identified as 'class'\n",
    "    if 'class' not in column_names:\n",
    "        column_names.insert(0, 'class')\n",
    "    \n",
    "    return column_names\n",
    "\n",
    "# Extracting column names\n",
    "column_names = extract_column_names(names_file_path)\n",
    "\n",
    "# Loading the dataset with the extracted column names\n",
    "data = pd.read_csv(data_file_path, header=None, names=column_names, sep=',')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e919f6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307ddcf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72d99430",
   "metadata": {},
   "source": [
    "## Eploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8753da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'class':\n",
      "class\n",
      "e    4208\n",
      "p    3916\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._cap_shape':\n",
      "._cap_shape\n",
      "x    3656\n",
      "f    3152\n",
      "k     828\n",
      "b     452\n",
      "s      32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._cap_surface':\n",
      "._cap_surface\n",
      "y    3244\n",
      "s    2556\n",
      "f    2320\n",
      "g       4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._cap_color':\n",
      "._cap_color\n",
      "n    2284\n",
      "g    1840\n",
      "e    1500\n",
      "y    1072\n",
      "w    1040\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._bruises?':\n",
      "._bruises?\n",
      "f    4748\n",
      "t    3376\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._odor':\n",
      "._odor\n",
      "n    3528\n",
      "f    2160\n",
      "y     576\n",
      "s     576\n",
      "a     400\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._gill_attachment':\n",
      "._gill_attachment\n",
      "f    7914\n",
      "a     210\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._gill_spacing':\n",
      "._gill_spacing\n",
      "c    6812\n",
      "w    1312\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._gill_size':\n",
      "._gill_size\n",
      "b    5612\n",
      "n    2512\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._gill_color':\n",
      "._gill_color\n",
      "b    1728\n",
      "p    1492\n",
      "w    1202\n",
      "n    1048\n",
      "g     752\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._stalk_shape':\n",
      "._stalk_shape\n",
      "t    4608\n",
      "e    3516\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._stalk_root':\n",
      "._stalk_root\n",
      "b    3776\n",
      "?    2480\n",
      "e    1120\n",
      "c     556\n",
      "r     192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._stalk_surface_above_ring':\n",
      "._stalk_surface_above_ring\n",
      "s    5176\n",
      "k    2372\n",
      "f     552\n",
      "y      24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._stalk_surface_below_ring':\n",
      "._stalk_surface_below_ring\n",
      "s    4936\n",
      "k    2304\n",
      "f     600\n",
      "y     284\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._stalk_color_above_ring':\n",
      "._stalk_color_above_ring\n",
      "w    4464\n",
      "p    1872\n",
      "g     576\n",
      "n     448\n",
      "b     432\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._stalk_color_below_ring':\n",
      "._stalk_color_below_ring\n",
      "w    4384\n",
      "p    1872\n",
      "g     576\n",
      "n     512\n",
      "b     432\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._veil_type':\n",
      "._veil_type\n",
      "p    8124\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._veil_color':\n",
      "._veil_color\n",
      "w    7924\n",
      "n      96\n",
      "o      96\n",
      "y       8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._ring_number':\n",
      "._ring_number\n",
      "o    7488\n",
      "t     600\n",
      "n      36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._ring_type':\n",
      "._ring_type\n",
      "p    3968\n",
      "e    2776\n",
      "l    1296\n",
      "f      48\n",
      "n      36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._spore_print_color':\n",
      "._spore_print_color\n",
      "w    2388\n",
      "n    1968\n",
      "k    1872\n",
      "h    1632\n",
      "r      72\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._population':\n",
      "._population\n",
      "v    4040\n",
      "y    1712\n",
      "s    1248\n",
      "n     400\n",
      "a     384\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column '._habitat':\n",
      "._habitat\n",
      "d    3148\n",
      "g    2148\n",
      "p    1144\n",
      "l     832\n",
      "u     368\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for column in data.columns:\n",
    "    print(f\"Column '{column}':\")\n",
    "    print(data[column].value_counts().head())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb41e02",
   "metadata": {},
   "source": [
    " it seems like there might be some missing values represented by a ?, I should Replace '?' with NaN: Convert '?' to NaN to standardize missing value representation with pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1039b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data.replace('?', np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8ea1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                            0\n",
       "._cap_shape                      0\n",
       "._cap_surface                    0\n",
       "._cap_color                      0\n",
       "._bruises?                       0\n",
       "._odor                           0\n",
       "._gill_attachment                0\n",
       "._gill_spacing                   0\n",
       "._gill_size                      0\n",
       "._gill_color                     0\n",
       "._stalk_shape                    0\n",
       "._stalk_root                  2480\n",
       "._stalk_surface_above_ring       0\n",
       "._stalk_surface_below_ring       0\n",
       "._stalk_color_above_ring         0\n",
       "._stalk_color_below_ring         0\n",
       "._veil_type                      0\n",
       "._veil_color                     0\n",
       "._ring_number                    0\n",
       "._ring_type                      0\n",
       "._spore_print_color              0\n",
       "._population                     0\n",
       "._habitat                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe420e0",
   "metadata": {},
   "source": [
    "# imputing missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac06f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed values and their counts: {'b': 1611, 'c': 107, 'e': 762}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Identify feature and response columns\n",
    "features = data.drop(columns=['._stalk_root'])  # Exclude target column for imputation\n",
    "response = data['._stalk_root'].fillna('missing')  # Fill missing values temporarily\n",
    "\n",
    "# Encode features (one-hot encoding)\n",
    "onehot_encoder = OneHotEncoder()\n",
    "features_encoded = onehot_encoder.fit_transform(features).toarray()\n",
    "\n",
    "# Encode response (label encoding)\n",
    "label_encoder = LabelEncoder()\n",
    "response_encoded = label_encoder.fit_transform(response)\n",
    "\n",
    "# Isolate data with and without missing '_stalk_root' values\n",
    "is_missing = data['._stalk_root'].isnull()\n",
    "if is_missing.sum() > 0:  # Proceed only if there are missing values\n",
    "    features_with_missing = features_encoded[is_missing]\n",
    "    features_without_missing = features_encoded[~is_missing]\n",
    "    response_without_missing = response_encoded[~is_missing]\n",
    "\n",
    "    # Initialize and train KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(features_without_missing, response_without_missing)\n",
    "\n",
    "    # Predict missing '_stalk_root' values\n",
    "    predicted_missing_encoded = knn.predict(features_with_missing)\n",
    "\n",
    "    # Decode predictions to original labels\n",
    "    predicted_missing = label_encoder.inverse_transform(predicted_missing_encoded)\n",
    "\n",
    "    # Impute missing values back into the original dataframe\n",
    "    data.loc[is_missing, '._stalk_root'] = predicted_missing\n",
    "\n",
    "# Ensure no missing values are left\n",
    "assert data['._stalk_root'].isnull().sum() == 0, \"There are still missing values in '._stalk_root'.\"\n",
    "\n",
    "# Optional: Print summary of imputation\n",
    "if 'predicted_missing' in locals():  # Check if imputation was performed\n",
    "    # Create the missing_values list with imputed values in their original form\n",
    "    missing_values = data.loc[is_missing, '._stalk_root'].tolist()\n",
    "\n",
    "    # Count unique values and their occurrences\n",
    "    unique_values, counts = np.unique(missing_values, return_counts=True)\n",
    "    missing_values_count = dict(zip(unique_values, counts))\n",
    "\n",
    "    # Print the unique imputed values and their counts\n",
    "    print(\"Imputed values and their counts:\", missing_values_count)\n",
    "else:\n",
    "    print(\"No missing values were found to impute.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f4eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffba60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a9da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65253650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57aa798a",
   "metadata": {},
   "source": [
    "## Concept Question #1  ## \n",
    "Why don’t we\n",
    "one-hot encode the response data to train the KNN model instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e16204",
   "metadata": {},
   "source": [
    "When working with the KNN algorithm, particularly for tasks like classification or imputing missing values, we typically don't one-hot encode the response data, because, KNN operates on the principle of finding the 'k' nearest neighbors based on distance calculations, such as Euclidean or Manhattan distance. It then assigns a class label to a new instance based on the majority vote among these neighbors. If we were to one-hot encode the response data, each category would be transformed into a separate dimension, and the concept of a \"majority vote\" would become less clear. This is because the algorithm would have to navigate through a multi-dimensional binary space to determine the nearest neighbors, complicating the prediction process.\n",
    "\n",
    "Als, Applying one-hot encoding to the response variable unnecessarily expands the dimensionality of the target space, making model training and prediction both more computationally demanding and harder to understand. Moreover, the intrinsic exclusivity of the categories, fundamental to the nature of the response variable, becomes less evident in this expanded, multi-dimensional format may result in information loss, with the model possibly interpreting these binary columns as independent features rather than as different states of a single variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d4322",
   "metadata": {},
   "source": [
    "\n",
    "#  Train a RandomForestClassifier as well as a LogisticRegression model to predictwhether a mushroom is edible or poisonous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ef870",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47968ad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Haneef\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Separate features and the target variable\n",
    "features = data.drop('class', axis=1)  # Dropping the target column to isolate features\n",
    "target = data['class']  # The target column indicating whether a mushroom is edible or poisonous\n",
    "\n",
    "# One-hot encode the feature data\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "features_encoded = onehot_encoder.fit_transform(features)\n",
    "\n",
    "# Label encode the target data\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Split the encoded data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e2d58-6b54-4b07-bae6-f0cca3beccd2",
   "metadata": {},
   "source": [
    "## Checking data prepared for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5597555e-8708-4a18-a6c0-c5b01e1a59df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "X_train: (6499, 116)\n",
      "X_test: (1625, 116)\n",
      "y_train: (6499,)\n",
      "y_test: (1625,)\n",
      "\n",
      "Data types:\n",
      "X_train type: float64\n",
      "y_train type: int32\n",
      "\n",
      "Target class distribution in y_train:\n",
      "0    0.517772\n",
      "1    0.482228\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target class distribution in y_test:\n",
      "0    0.518769\n",
      "1    0.481231\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sparsity in X_train: 0.81\n",
      "Sparsity in X_test: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the datasets\n",
    "print(\"Shapes of the datasets:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\\n\")\n",
    "\n",
    "# Check the data types\n",
    "print(\"Data types:\")\n",
    "print(f\"X_train type: {X_train.dtype}\")\n",
    "print(f\"y_train type: {y_train.dtype}\\n\")\n",
    "\n",
    "# Check the balance of the target classes\n",
    "print(\"Target class distribution in y_train:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "print(\"\\nTarget class distribution in y_test:\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True))\n",
    "\n",
    "\n",
    "sparsity = lambda x: 1.0 - (np.count_nonzero(x) / float(x.size))\n",
    "print(f\"\\nSparsity in X_train: {sparsity(X_train):.2f}\")\n",
    "print(f\"Sparsity in X_test: {sparsity(X_test):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531becef-5bec-4c4f-a783-7b17108111cf",
   "metadata": {},
   "source": [
    "# Training the LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a408190d-be2d-436f-b2a7-ebcedcb6a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression model: 0.9994\n",
      "CPU times: total: 250 ms\n",
      "Wall time: 301 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the LogisticRegression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Accuracy of LogisticRegression model: {accuracy_logistic:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c03a1-9f9b-40d3-804f-f06b95a89442",
   "metadata": {},
   "source": [
    "## Training the RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "124e0c54-ba86-401b-8491-7fbb67280ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier model: 1.0000\n",
      "CPU times: total: 1 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the RandomForestClassifier model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = random_forest_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy of RandomForestClassifier model: {accuracy_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80358047-b8b3-41c6-99ca-c8ca780b7f32",
   "metadata": {},
   "source": [
    "# Compute the accuracy, precision, and recall scores for a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1b3a8-3dc1-4462-a183-2d94219d4962",
   "metadata": {},
   "source": [
    "## Evaluating the LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6499e55f-39a9-47be-9b8c-419a0325f82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Model Evaluation:\n",
      "Accuracy: 0.9994\n",
      "Precision: 0.9987\n",
      "Recall: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Predictions were made previously as y_pred_logistic\n",
    "# compute the metrics for the LogisticRegression model\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "precision_logistic = precision_score(y_test, y_pred_logistic)\n",
    "recall_logistic = recall_score(y_test, y_pred_logistic)\n",
    "\n",
    "print(\"LogisticRegression Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_logistic:.4f}\")\n",
    "print(f\"Precision: {precision_logistic:.4f}\")\n",
    "print(f\"Recall: {recall_logistic:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1677fc5b-0c24-477a-84f0-0d3ddeb34b1e",
   "metadata": {},
   "source": [
    "## Evaluating the RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc4119a6-5b10-4865-94db-0a5b7a1055c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Model Evaluation:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Predictions were made previously as y_pred_rf\n",
    "# compute the metrics for the RandomForestClassifier model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"RandomForestClassifier Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Precision: {precision_rf:.4f}\")\n",
    "print(f\"Recall: {recall_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a11efb-51a2-484f-90d4-a79176cf68a0",
   "metadata": {},
   "source": [
    "### model performance discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57daf96d-d9dc-4b07-991b-e490ab10371e",
   "metadata": {},
   "source": [
    "The performance metrics for your Logistic Regression and Random Forest Classifier models suggest extremely high, if not perfect, levels of prediction accuracy, precision, and recall. While at first glance, these metrics indicate that both models are performing exceptionally well, they also raise the possibility of overfitting, especially in the case of the RandomForestClassifier, which has perfect scores across all evaluated metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68b351-9a0d-4c54-9349-df1b2b10a93a",
   "metadata": {},
   "source": [
    "## Concept Question #2:Could we trainthese two models by one-hot encoding the response data instead, being careful tospecify that the drop parameter of the OneHotEncoder class is set to ‘first’? Why or whynot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b48a13b-4b40-402b-82d7-24f603bc4ae3",
   "metadata": {},
   "source": [
    "whether to use one-hot encoding, especially with a binary target like predicting if a mushroom is edible or poisonous, opens up a discussion on dimensions, complexity, and computing time.\n",
    "\n",
    "One-hot encoding the response data, despite being a powerful tool for feature preprocessing, introduces unnecessary complexity when applied to a binary target variable. This method transforms our straightforward binary labels into a two-column matrix for the two classes. However, in binary classification tasks, our models are designed to predict the probability of samples belonging to a single class. By adding an extra step of one-hot encoding and then reducing the dimensions back down by dropping one of the columns (using drop='first'), we inadvertently complicate the data preparation process without any gain in performance or interpretability.\n",
    "\n",
    "This unnecessary increase in dimensions, even if momentarily before reduction, adds to the computational workload. It means our machine has to handle more data transformations, which can  increase the computing time and complexity of our data pipeline. For binary classification tasks, label encoding achieves the desired format—assigning a unique integer to each class—without increasing the dimensionality of the target data. It's a more direct and efficient way to prepare our response variable, allowing the model to focus on learning from the data rather than deciphering the structure of the target variable.\n",
    "\n",
    "finally, while one-hot encoding is essential for categorical features without a natural order, applying it to a binary response variable and then reducing the dimensions isn't necessary. It complicates the preprocessing step and could lead to slight increases in computing time, without offering benefits in model performance or clarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde5166-6b76-406d-bee5-534cb9145129",
   "metadata": {},
   "source": [
    "### model performance discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89440666-e0ac-4206-b910-aa997d83e895",
   "metadata": {},
   "source": [
    "he RandomForestClassifier model achieves perfect scores in accuracy, precision, and recall, making it the superior model based on these metrics. However, the LogisticRegression model's performance is also outstanding and only marginally less perfect in terms of precision.\n",
    "\n",
    "In practical terms, the high precision of both models means that they are very reliable at predicting poisonous mushrooms, which is crucial for safety reasons—false positives (edible mushrooms incorrectly labeled as poisonous) are minimal. The perfect recall score, particularly important in this context, ensures that there are no false negatives (poisonous mushrooms incorrectly labeled as edible), which could potentially be dangerous.\n",
    "\n",
    "The high performance might indicate that the dataset features strongly predict whether a mushroom is edible or poisonous, allowing both models to learn effective decision boundaries.\n",
    "to summarize, \n",
    " both models perform exceptionally well on this dataset, with RandomForestClassifier slightly outperforming LogisticRegression in precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba378c57-b5c3-4d20-a451-da5b775af210",
   "metadata": {},
   "source": [
    "# Performing dimensionality reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecfabc81-4006-404e-aa3e-2b13c2ee8af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of X_train: (6499, 60)\n",
      "New shape of X_test: (1625, 60)\n",
      "Number of components retained to preserve 95% of variance: 60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize PCA to keep 95% of the variance\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "# Fit PCA on the training data and transform both training and test data\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Check the new shape of the datasets and the number of components\n",
    "print(f\"New shape of X_train: {X_train_pca.shape}\")\n",
    "print(f\"New shape of X_test: {X_test_pca.shape}\")\n",
    "print(f\"Number of components retained to preserve 95% of variance: {pca.n_components_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc6ecda-f5aa-4c02-99f1-d5465bc3394b",
   "metadata": {},
   "source": [
    "## results of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b67c5ae0-569b-4b4c-8347-229cff893d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of features: 116\n",
      "Number of features after PCA dimensionality reduction: 60\n",
      "Percentage reduction in dimensions: 48.28%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_dimensions = X_train.shape[1]  \n",
    "\n",
    "# Number of dimensions/features after PCA dimensionality reduction\n",
    "reduced_dimensions = X_train_pca.shape[1]  \n",
    "\n",
    "# Calculate the percentage reduction in dimensions\n",
    "percentage_reduction = ((initial_dimensions - reduced_dimensions) / initial_dimensions) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f\"Initial number of features: {initial_dimensions}\")\n",
    "print(f\"Number of features after PCA dimensionality reduction: {reduced_dimensions}\")\n",
    "print(f\"Percentage reduction in dimensions: {percentage_reduction:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78788b9-c532-411e-a089-72ca209e9370",
   "metadata": {},
   "source": [
    "# training new models on reduced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d3b083-9474-45ec-aa88-078671ce1d3d",
   "metadata": {},
   "source": [
    "## Training the LogisticRegression Model on the Reduced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6840cd67-4142-41c0-963b-6fae75d60762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression model on reduced dataset: 1.0000\n",
      "CPU times: total: 266 ms\n",
      "Wall time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the LogisticRegression model\n",
    "logistic_model_reduced = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the reduced dataset\n",
    "logistic_model_reduced.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set and evaluate the model\n",
    "y_pred_logistic_reduced = logistic_model_reduced.predict(X_test_pca)\n",
    "accuracy_logistic_reduced = accuracy_score(y_test, y_pred_logistic_reduced)\n",
    "print(f\"Accuracy of LogisticRegression model on reduced dataset: {accuracy_logistic_reduced:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d08e8-9c17-45d3-9a19-f64bbce71746",
   "metadata": {},
   "source": [
    "## Training the RandomForestClassifier Model on the Reduced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06a327b0-2d40-4020-81f1-91774e568458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier model on reduced dataset: 1.0000\n",
      "CPU times: total: 7.91 s\n",
      "Wall time: 8.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the RandomForestClassifier model with a random state\n",
    "random_forest_model_reduced = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the reduced dataset\n",
    "random_forest_model_reduced.fit(X_train_pca, y_train)\n",
    "\n",
    "#  Make predictions on the test set and evaluate the model\n",
    "y_pred_rf_reduced = random_forest_model_reduced.predict(X_test_pca)\n",
    "accuracy_rf_reduced = accuracy_score(y_test, y_pred_rf_reduced)\n",
    "print(f\"Accuracy of RandomForestClassifier model on reduced dataset: {accuracy_rf_reduced:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30a6bd-7538-4372-ba29-027b07b9a17c",
   "metadata": {},
   "source": [
    "# Computing the accuracy, precision, and recall scores for the model trained on the reduced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b5af23-5708-441a-82bb-b5492a1ddbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Full Data</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.998723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>PCA Reduced</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Full Data</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>PCA Reduced</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      Dataset  Accuracy  Precision  Recall  Time (s)\n",
       "0  Logistic Regression    Full Data  0.999385   0.998723     1.0     0.450\n",
       "1  Logistic Regression  PCA Reduced  1.000000   1.000000     1.0     0.201\n",
       "2        Random Forest    Full Data  1.000000   1.000000     1.0     1.750\n",
       "3        Random Forest  PCA Reduced  1.000000   1.000000     1.0    11.200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# Calculate precision and recall for the Logistic Regression model on the reduced dataset\n",
    "precision_logistic_reduced = precision_score(y_test, y_pred_logistic_reduced)\n",
    "recall_logistic_reduced = recall_score(y_test, y_pred_logistic_reduced)\n",
    "\n",
    "# Calculate precision and recall for the Random Forest model on the reduced dataset\n",
    "precision_rf_reduced = precision_score(y_test, y_pred_rf_reduced)\n",
    "recall_rf_reduced = recall_score(y_test, y_pred_rf_reduced)\n",
    "\n",
    "# Compile all metrics into a DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Logistic Regression', 'Logistic Regression',\n",
    "        'Random Forest', 'Random Forest'\n",
    "    ],\n",
    "    'Dataset': [\n",
    "        'Full Data', 'PCA Reduced',\n",
    "        'Full Data', 'PCA Reduced'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_logistic, accuracy_logistic_reduced,\n",
    "        accuracy_rf, accuracy_rf_reduced\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_logistic, precision_logistic_reduced,\n",
    "        precision_rf, precision_rf_reduced\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_logistic, recall_logistic_reduced,\n",
    "        recall_rf, recall_rf_reduced\n",
    "    ],\n",
    "    'Time (s)': [\n",
    "        0.450, 0.201,  # Times for Logistic Regression on full and reduced data\n",
    "        1.75, 11.2     # Times for Random Forest on full and reduced data\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcaf48-cb0a-40ed-a673-29f0aa3957db",
   "metadata": {},
   "source": [
    "## Preparing tabular output for modelcomparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea8f7ea5-b825-4a54-860d-3a10b779dd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Full Data</th>\n",
       "      <th>PCA Reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.999385</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.998723</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Random Forest</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>1.750000</td>\n",
       "      <td>11.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Full Data  PCA Reduced\n",
       "Logistic Regression Accuracy    0.999385        1.000\n",
       "                    Precision   0.998723        1.000\n",
       "                    Recall      1.000000        1.000\n",
       "                    Time        0.450000        0.201\n",
       "Random Forest       Accuracy    1.000000        1.000\n",
       "                    Precision   1.000000        1.000\n",
       "                    Recall      1.000000        1.000\n",
       "                    Time        1.750000       11.200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "\n",
    "y_test = []\n",
    "y_pred_logistic = []\n",
    "y_pred_rf = []\n",
    "y_pred_logistic_reduced  \n",
    "y_pred_rf_reduced = []\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "metrics_data = {\n",
    "    ('Logistic Regression', 'Accuracy'): [accuracy_logistic, accuracy_logistic_reduced],\n",
    "    ('Logistic Regression', 'Precision'): [precision_logistic, precision_logistic_reduced],\n",
    "    ('Logistic Regression', 'Recall'): [recall_logistic, recall_logistic_reduced],\n",
    "    ('Logistic Regression', 'Time'): [0.450, 0.201],\n",
    "    ('Random Forest', 'Accuracy'): [accuracy_rf, accuracy_rf_reduced],\n",
    "    ('Random Forest', 'Precision'): [precision_rf, precision_rf_reduced],\n",
    "    ('Random Forest', 'Recall'): [recall_rf, recall_rf_reduced],\n",
    "    ('Random Forest', 'Time'): [1.750, 11.200]\n",
    "}\n",
    "\n",
    "# The metrics DataFrame with multi-index\n",
    "multi_index = pd.MultiIndex.from_tuples(metrics_data.keys())\n",
    "metrics_df = pd.DataFrame(list(metrics_data.values()), index=multi_index, columns=['Full Data', 'PCA Reduced'])\n",
    "\n",
    "# Display the DataFrame\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6e505-0715-4c14-b02d-f6eefde97651",
   "metadata": {},
   "source": [
    "## model comparion discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9cbed-b3a8-48dc-b175-990c30eded36",
   "metadata": {},
   "source": [
    "\n",
    "Looking at the training times and performance metrics of Logistic Regression and Random Forest on both full and PCA reduced datasets, it's interisting to see how they vary. With Logistic Regression, the drop in training time when using the PCA reduced dataset is quite noticable, which makes sense because reducing the number of features should ideally speed things up. However, for the Random Forest, the increase in training time for the PCA reduced data is puzzling; it's not what I had expected given that fewer features typically lead to quicker training. Performance-wise, both models score perfectly on precision and recall, which initially seems great, but I can't help wondering if the models might be  indicative of overfitting. Such perfect scores could signal overfitting, especially if the test data are too similar to the training set. but, it's also possible that the data is just inherently well-structured, allowing both models to perform very well. Comparatively, the slight improvement in Logistic Regression's accuracy with the reduced dataset could be meaningful, but it's the vastly different training times that really catch my attention and make me curious about the underlying reasons. finally,\n",
    "When comparing the performances of the full and reduced models, it's clear that dimensionality reduction through PCA has nuanced impacts. For Logistic Regression, the transition to a reduced dataset not only slashes training time but also nudges accuracy upward ever so slightly, hinting at the efficiency of the model with fewer dimensions. On the other hand, the Random Forest model, with its performance metrics unaltered, suggests a robustness to dimensionality changes but at a cost of increased training time, which raises questions about efficiency. while Random Forest's complexity management doesn't translate into faster performance,it seems to be  an aspect worth exploring further to understand the dynamics between model complexity and data dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde5f513-4d73-40d0-bb8c-8e444d0cf6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
